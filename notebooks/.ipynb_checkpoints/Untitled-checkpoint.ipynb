{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37cf11b-f61a-40f4-90f5-355c4f7ee16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import sys, random, uuid\n",
    "    from pyspark.context import SparkContext\n",
    "    from pyspark.sql.session import SparkSession\n",
    "    from pyspark.sql.functions import col, to_timestamp, monotonically_increasing_id, to_date, when, lit\n",
    "    from pyspark.sql.functions import *\n",
    "    from pyspark.sql.types import *\n",
    "    from datetime import datetime, date\n",
    "    import boto3\n",
    "    from functools import reduce\n",
    "    from pyspark.sql import Row\n",
    "    from faker import Faker\n",
    "except Exception as e:\n",
    "    print(\"Modules are missing : {} \".format(e))\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "job_start_ts = datetime.now()\n",
    "ts_format = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "# MinIO connection\n",
    "minio_endpoint = 'http://minio:9000'\n",
    "minio_access_key = 'admin'\n",
    "minio_secret_key = 'password'\n",
    "minio_secure = False\n",
    "\n",
    "# Spark Master URL (inside docker network)\n",
    "spark_master_url = \"spark://spark-master:7077\"\n",
    "\n",
    "# ==================== SPARK SESSION ====================\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Jupyter-Spark-MinIO\")\n",
    "    .master(\"spark://spark-master:7077\")  # <--- CONNECT TO SPARK CLUSTER HERE\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.spark.sql.hudi.HoodieSparkSessionExtension\")\n",
    "    .config(\"className\", \"org.apache.hudi\")\n",
    "    .config(\"spark.sql.hive.convertMetastoreParquet\", \"false\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(f\"✅ Connected to Spark Master at: {spark_master_url}\")\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "\n",
    "# ==================== MINIO / S3 CONFIG ====================\n",
    "hadoop_conf = spark._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.s3a.endpoint\", minio_endpoint)\n",
    "hadoop_conf.set(\"fs.s3a.access.key\", minio_access_key)\n",
    "hadoop_conf.set(\"fs.s3a.secret.key\", minio_secret_key)\n",
    "hadoop_conf.set(\"fs.s3a.path.style.access\", \"true\")\n",
    "hadoop_conf.set(\"fs.s3a.connection.ssl.enabled\", str(minio_secure).lower())\n",
    "hadoop_conf.set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "hadoop_conf.set(\"fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "\n",
    "print(\"✅ Spark and MinIO configuration completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
