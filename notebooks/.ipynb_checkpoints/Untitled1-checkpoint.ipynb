{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80b8cd-5a06-400c-9d36-a1c7cab78b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# minio_endpoint = 'http://minio:9000'\n",
    "# minio_access_key = 'admin'\n",
    "# minio_secret_key = 'password'\n",
    "\n",
    "# spark = (\n",
    "#     SparkSession.builder\n",
    "#     .appName(\"Jupyter-External-Spark\")\n",
    "#     .master(\"spark://spark-master:7077\")\n",
    "#     # --- Critical driver configs (for worker -> driver communication) ---\n",
    "#     .config(\"spark.driver.host\", \"jupyter-spark\")   # must match container name\n",
    "#     .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "#     .config(\"spark.driver.port\", \"4041\")\n",
    "#     .config(\"spark.blockManager.port\", \"4042\")\n",
    "#     # --- S3A / MinIO configs ---\n",
    "#     .config(\"spark.hadoop.fs.s3a.endpoint\", minio_endpoint)\n",
    "#     .config(\"spark.hadoop.fs.s3a.access.key\", minio_access_key)\n",
    "#     .config(\"spark.hadoop.fs.s3a.secret.key\", minio_secret_key)\n",
    "#     .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "#     .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "#     .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "#     .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\",\n",
    "#             \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "#     # --- Pass credentials to executors ---\n",
    "#     .config(\"spark.executorEnv.AWS_ACCESS_KEY_ID\", minio_access_key)\n",
    "#     .config(\"spark.executorEnv.AWS_SECRET_ACCESS_KEY\", minio_secret_key)\n",
    "#     .getOrCreate()\n",
    "# )\n",
    "\n",
    "# print(\"✅ SparkSession connected successfully!\")\n",
    "# print(\"Master:\", spark.sparkContext.master)\n",
    "# print(\"Driver host:\", spark.conf.get(\"spark.driver.host\"))\n",
    "\n",
    "\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# driver_ip = \"172.18.0.11\"  # replace with your actual output above\n",
    "\n",
    "# spark = (\n",
    "#     SparkSession.builder\n",
    "#     .appName(\"Jupyter-External-Spark\")\n",
    "#     .master(\"spark://spark-master:7077\")\n",
    "#     .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "#     .config(\"spark.driver.host\", driver_ip)   # use direct IP instead of hostname\n",
    "#     .config(\"spark.driver.port\", \"4041\")\n",
    "#     .config(\"spark.blockManager.port\", \"4042\")\n",
    "#     .config(\"spark.network.timeout\", \"120s\")\n",
    "#     .config(\"spark.executor.heartbeatInterval\", \"30s\")\n",
    "#     .getOrCreate()\n",
    "# )\n",
    "\n",
    "# print(\"✅ Connected to:\", spark.sparkContext.master)\n",
    "# print(\"Driver:\", spark.conf.get(\"spark.driver.host\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1) Force-stop any existing SparkContext (safe to run)\n",
    "from pyspark import SparkContext\n",
    "try:\n",
    "    sc = SparkContext.getOrCreate()\n",
    "    # sc may be stopped already; stop() will be no-op if already stopped\n",
    "    sc.stop()\n",
    "except Exception as e:\n",
    "    # ignore errors while stopping\n",
    "    print(\"stop() exception (ignored):\", e)\n",
    "\n",
    "# 2) Now create a clean SparkSession that connects to external cluster\n",
    "from pyspark.sql import SparkSession\n",
    "minio_endpoint = 'http://minio:9000'\n",
    "minio_access_key = 'admin'\n",
    "minio_secret_key = 'password'\n",
    "driver_ip = \"172.18.0.11\"   # e.g. '172.18.0.5' or 'jupyter-spark'\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Jupyter-External-Spark\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "    .config(\"spark.driver.host\", driver_ip)\n",
    "    .config(\"spark.driver.port\", \"4041\")\n",
    "    .config(\"spark.blockManager.port\", \"4042\")\n",
    "    .config(\"spark.network.timeout\", \"120s\")\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"30s\")\n",
    "    # MinIO / S3A\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", minio_endpoint)\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", minio_access_key)\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", minio_secret_key)\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "    # ensure executors have creds\n",
    "    .config(\"spark.executorEnv.AWS_ACCESS_KEY_ID\", minio_access_key)\n",
    "    .config(\"spark.executorEnv.AWS_SECRET_ACCESS_KEY\", minio_secret_key)\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(\"Spark master:\", spark.sparkContext.master)\n",
    "print(\"Driver:\", spark.conf.get(\"spark.driver.host\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548def36-ea78-46d8-bc07-ee406bcb28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.range(0, 10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a97ca7-d1f1-4c0e-9c19-799d23bc662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = spark.read.json('s3a://test/orders.json')\n",
    "\n",
    "# average = dataframe.agg({'amount':'avg'})\n",
    "\n",
    "# #average.write.format(\"csv\").option(\"header\", \"true\").save(\"s3a://test/json/\")\n",
    "\n",
    "# average.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
