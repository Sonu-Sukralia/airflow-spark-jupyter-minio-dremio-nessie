{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa5f918-6dc8-483d-8b17-df472b52cf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stopped previous SparkContext\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "try:\n",
    "    sc = SparkContext.getOrCreate()\n",
    "    sc.stop()\n",
    "    print(\"✅ Stopped previous SparkContext\")\n",
    "except Exception as e:\n",
    "    print(\"Already stopped or none running:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5afe60-c413-44b8-9a2f-12fd1ae42548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "driver_ip = \"172.18.0.11\"  # Jupyter container IP (you verified this)\n",
    "minio_endpoint = \"http://minio:9000\"\n",
    "minio_access_key = \"admin\"\n",
    "minio_secret_key = \"password\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Jupyter-External-Spark\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    # --- Critical network settings ---\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "    .config(\"spark.driver.host\", driver_ip)\n",
    "    .config(\"spark.driver.port\", \"4041\")                # Fixed port for executor→driver RPC\n",
    "    .config(\"spark.blockManager.port\", \"4042\")          # Fixed port for block manager\n",
    "    .config(\"spark.network.timeout\", \"120s\")\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"30s\")\n",
    "    # --- MinIO / S3A config ---\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", minio_endpoint)\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", minio_access_key)\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", minio_secret_key)\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\",\n",
    "            \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "    # --- Pass credentials to executors ---\n",
    "    .config(\"spark.executorEnv.AWS_ACCESS_KEY_ID\", minio_access_key)\n",
    "    .config(\"spark.executorEnv.AWS_SECRET_ACCESS_KEY\", minio_secret_key)\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(\"✅ Spark connected successfully!\")\n",
    "print(\"Master:\", spark.sparkContext.master)\n",
    "print(\"Driver host:\", spark.conf.get(\"spark.driver.host\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
